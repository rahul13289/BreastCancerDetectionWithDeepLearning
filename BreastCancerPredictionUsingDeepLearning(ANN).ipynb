{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqvAXZfIV5sz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('data.csv')"
      ],
      "metadata": {
        "id": "v9svfWJiYP3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "crpSIID7c1he",
        "outputId": "d5fe2567-929a-44aa-a3ef-12b0525bdb25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31d44992-07a1-44a3-8d44-d9f43c439e2f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31d44992-07a1-44a3-8d44-d9f43c439e2f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31d44992-07a1-44a3-8d44-d9f43c439e2f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31d44992-07a1-44a3-8d44-d9f43c439e2f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Encode the target variable 'diagnosis'\n",
        "# Drop the 'Unnamed: 32' column\n",
        "df.drop(labels = 'Unnamed: 32', inplace=True,axis = 1)\n",
        "\n",
        "# Encode the target variable 'diagnosis'\n",
        "x = df.iloc[:,2:].values\n",
        "y = df.iloc[:,1].values\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "ORUyHw6jG0XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.1, random_state=0)"
      ],
      "metadata": {
        "id": "aTiLRZMIIeH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "fHTesPaMZlx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "model = Sequential([\n",
        "    Dense(32, input_shape=(X_train.shape[1],), activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "NQBOBoiQZN4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture and compile it\n",
        "model = Sequential()\n",
        "model.add(Dense(16,activation='relu', input_shape = (30,)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(16,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense( 1 , activation='sigmoid'))\n",
        "model.compile(optimizer='adam',loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjbiMNS4KihE",
        "outputId": "d48722a5-ad63-4c6e-971b-3cc3bf37410d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 16)                496       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 785\n",
            "Trainable params: 785\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train, batch_size = 100, epochs = 150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOMJdMtVKlpK",
        "outputId": "1452833e-44da-4030-ed19-7710f1f9c299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "6/6 [==============================] - 1s 4ms/step - loss: 0.7666 - accuracy: 0.5273\n",
            "Epoch 2/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.6133\n",
            "Epoch 3/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.7070\n",
            "Epoch 4/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7656\n",
            "Epoch 5/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.8145\n",
            "Epoch 6/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.8262\n",
            "Epoch 7/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8711\n",
            "Epoch 8/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8672\n",
            "Epoch 9/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8926\n",
            "Epoch 10/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.9062\n",
            "Epoch 11/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8965\n",
            "Epoch 12/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.9160\n",
            "Epoch 13/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2935 - accuracy: 0.9180\n",
            "Epoch 14/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.9258\n",
            "Epoch 15/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2593 - accuracy: 0.9219\n",
            "Epoch 16/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2341 - accuracy: 0.9375\n",
            "Epoch 17/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2305 - accuracy: 0.9355\n",
            "Epoch 18/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2301 - accuracy: 0.9258\n",
            "Epoch 19/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2134 - accuracy: 0.9336\n",
            "Epoch 20/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9355\n",
            "Epoch 21/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1937 - accuracy: 0.9453\n",
            "Epoch 22/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1832 - accuracy: 0.9531\n",
            "Epoch 23/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.9609\n",
            "Epoch 24/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1725 - accuracy: 0.9512\n",
            "Epoch 25/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1586 - accuracy: 0.9629\n",
            "Epoch 26/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1672 - accuracy: 0.9590\n",
            "Epoch 27/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9551\n",
            "Epoch 28/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.9570\n",
            "Epoch 29/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9688\n",
            "Epoch 30/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1414 - accuracy: 0.9688\n",
            "Epoch 31/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.1386 - accuracy: 0.9629\n",
            "Epoch 32/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9727\n",
            "Epoch 33/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9668\n",
            "Epoch 34/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9668\n",
            "Epoch 35/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.1210 - accuracy: 0.9648\n",
            "Epoch 36/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 0.9727\n",
            "Epoch 37/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.1120 - accuracy: 0.9727\n",
            "Epoch 38/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.9727\n",
            "Epoch 39/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9727\n",
            "Epoch 40/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1058 - accuracy: 0.9707\n",
            "Epoch 41/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0978 - accuracy: 0.9785\n",
            "Epoch 42/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.9746\n",
            "Epoch 43/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.9746\n",
            "Epoch 44/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0974 - accuracy: 0.9766\n",
            "Epoch 45/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9766\n",
            "Epoch 46/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0889 - accuracy: 0.9766\n",
            "Epoch 47/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1050 - accuracy: 0.9727\n",
            "Epoch 48/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0853 - accuracy: 0.9805\n",
            "Epoch 49/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0869 - accuracy: 0.9766\n",
            "Epoch 50/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0902 - accuracy: 0.9785\n",
            "Epoch 51/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0854 - accuracy: 0.9766\n",
            "Epoch 52/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0892 - accuracy: 0.9785\n",
            "Epoch 53/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0843 - accuracy: 0.9746\n",
            "Epoch 54/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.9785\n",
            "Epoch 55/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9844\n",
            "Epoch 56/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0868 - accuracy: 0.9785\n",
            "Epoch 57/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 0.9766\n",
            "Epoch 58/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9766\n",
            "Epoch 59/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9785\n",
            "Epoch 60/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0793 - accuracy: 0.9785\n",
            "Epoch 61/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0767 - accuracy: 0.9805\n",
            "Epoch 62/150\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 0.9805\n",
            "Epoch 63/150\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9844\n",
            "Epoch 64/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.9805\n",
            "Epoch 65/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0783 - accuracy: 0.9805\n",
            "Epoch 66/150\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0715 - accuracy: 0.9727\n",
            "Epoch 67/150\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.9785\n",
            "Epoch 68/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9805\n",
            "Epoch 69/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.9805\n",
            "Epoch 70/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9805\n",
            "Epoch 71/150\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0717 - accuracy: 0.9824\n",
            "Epoch 72/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0752 - accuracy: 0.9824\n",
            "Epoch 73/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9805\n",
            "Epoch 74/150\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0742 - accuracy: 0.9805\n",
            "Epoch 75/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0716 - accuracy: 0.9805\n",
            "Epoch 76/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.9766\n",
            "Epoch 77/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9805\n",
            "Epoch 78/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9883\n",
            "Epoch 79/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9844\n",
            "Epoch 80/150\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9824\n",
            "Epoch 81/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9805\n",
            "Epoch 82/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9766\n",
            "Epoch 83/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.9766\n",
            "Epoch 84/150\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9844\n",
            "Epoch 85/150\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.9863\n",
            "Epoch 86/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.9805\n",
            "Epoch 87/150\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9863\n",
            "Epoch 88/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9844\n",
            "Epoch 89/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9863\n",
            "Epoch 90/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.9883\n",
            "Epoch 91/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9824\n",
            "Epoch 92/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.9883\n",
            "Epoch 93/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9863\n",
            "Epoch 94/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 0.9883\n",
            "Epoch 95/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9844\n",
            "Epoch 96/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.9824\n",
            "Epoch 97/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9883\n",
            "Epoch 98/150\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0646 - accuracy: 0.9824\n",
            "Epoch 99/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.9844\n",
            "Epoch 100/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9863\n",
            "Epoch 101/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9883\n",
            "Epoch 102/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9863\n",
            "Epoch 103/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9844\n",
            "Epoch 104/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.9863\n",
            "Epoch 105/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9844\n",
            "Epoch 106/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9883\n",
            "Epoch 107/150\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0563 - accuracy: 0.9863\n",
            "Epoch 108/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9863\n",
            "Epoch 109/150\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0397 - accuracy: 0.9883\n",
            "Epoch 110/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0480 - accuracy: 0.9902\n",
            "Epoch 111/150\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0529 - accuracy: 0.9883\n",
            "Epoch 112/150\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0593 - accuracy: 0.9844\n",
            "Epoch 113/150\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0549 - accuracy: 0.9805\n",
            "Epoch 114/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0536 - accuracy: 0.9863\n",
            "Epoch 115/150\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0561 - accuracy: 0.9844\n",
            "Epoch 116/150\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0476 - accuracy: 0.9883\n",
            "Epoch 117/150\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0552 - accuracy: 0.9883\n",
            "Epoch 118/150\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0409 - accuracy: 0.9883\n",
            "Epoch 119/150\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0550 - accuracy: 0.9805\n",
            "Epoch 120/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0535 - accuracy: 0.9844\n",
            "Epoch 121/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0558 - accuracy: 0.9863\n",
            "Epoch 122/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0475 - accuracy: 0.9883\n",
            "Epoch 123/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9883\n",
            "Epoch 124/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9883\n",
            "Epoch 125/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9824\n",
            "Epoch 126/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9922\n",
            "Epoch 127/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9902\n",
            "Epoch 128/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9883\n",
            "Epoch 129/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9863\n",
            "Epoch 130/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9883\n",
            "Epoch 131/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 0.9863\n",
            "Epoch 132/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9902\n",
            "Epoch 133/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9902\n",
            "Epoch 134/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9902\n",
            "Epoch 135/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9883\n",
            "Epoch 136/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9863\n",
            "Epoch 137/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9883\n",
            "Epoch 138/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9902\n",
            "Epoch 139/150\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0415 - accuracy: 0.9922\n",
            "Epoch 140/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9863\n",
            "Epoch 141/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9883\n",
            "Epoch 142/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9883\n",
            "Epoch 143/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0416 - accuracy: 0.9902\n",
            "Epoch 144/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9902\n",
            "Epoch 145/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9883\n",
            "Epoch 146/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.9922\n",
            "Epoch 147/150\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0388 - accuracy: 0.9922\n",
            "Epoch 148/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9902\n",
            "Epoch 149/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0483 - accuracy: 0.9863\n",
            "Epoch 150/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.9922\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f73b941ad00>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set and calculate confusion matrix\n",
        "pred = model.predict(X_test)\n",
        "pred = (pred > 0.5)\n",
        "cm = confusion_matrix(y_test,pred)\n",
        "\n",
        "# Plot the confusion matrix using seaborn heatmap\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "5pWL4UQKKsop",
        "outputId": "8cf3ff37-b6a8-4405-9394-095d8e30a350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ESQ1_8FRZtOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwYfgLMKZP5x",
        "outputId": "8bc04d7f-7056-4a28-9015-c29427128d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "8/8 [==============================] - 1s 33ms/step - loss: 0.0471 - accuracy: 0.9824 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0418 - accuracy: 0.9844 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0321 - accuracy: 0.9902 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9883 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0367 - accuracy: 0.9922 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0406 - accuracy: 0.9863 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 0.9902 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9902 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0320 - accuracy: 0.9902 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0367 - accuracy: 0.9844 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9922 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0436 - accuracy: 0.9883 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0409 - accuracy: 0.9902 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0324 - accuracy: 0.9902 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0361 - accuracy: 0.9883 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 0.9883 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0301 - accuracy: 0.9922 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 0.9902 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0323 - accuracy: 0.9902 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0310 - accuracy: 0.9922 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9922 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.9883 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0286 - accuracy: 0.9902 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0284 - accuracy: 0.9922 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 0.9902 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0294 - accuracy: 0.9902 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9902 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9902 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0278 - accuracy: 0.9922 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0301 - accuracy: 0.9922 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.9902 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9941 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0273 - accuracy: 0.9922 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0366 - accuracy: 0.9902 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 0.9922 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0220 - accuracy: 0.9922 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0326 - accuracy: 0.9883 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0207 - accuracy: 0.9922 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0219 - accuracy: 0.9941 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0231 - accuracy: 0.9922 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0187 - accuracy: 0.9922 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 0.9883 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 0.9922 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0140 - accuracy: 0.9980 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0221 - accuracy: 0.9922 - val_loss: 0.0111 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLffpD6kZzT6",
        "outputId": "3cd41c5a-49ad-4e8a-9be5-ee3df0f4b6df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0111 - accuracy: 1.0000\n",
            "Test accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}